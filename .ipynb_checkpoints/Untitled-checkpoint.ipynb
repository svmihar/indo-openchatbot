{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fine-tuning the library models for language modeling on a text file (GPT, GPT-2, BERT, RoBERTa).\n",
    "GPT and GPT-2 are fine-tuned using a causal language modeling (CLM) loss while BERT and RoBERTa are fine-tuned\n",
    "using a masked language modeling (MLM) loss.\n",
    "\"\"\"\n",
    "\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from transformers import (\n",
    "    MODEL_WITH_LM_HEAD_MAPPING,\n",
    "    WEIGHTS_NAME,\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModelWithLMHead,\n",
    "    AutoTokenizer,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except ImportError:\n",
    "    from tensorboardX import SummaryWriter\n",
    "\n",
    "# Configs\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_WITH_LM_HEAD_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "# Args to allow for easy convertion of python script to notebook\n",
    "class Args():\n",
    "    def __init__(self):\n",
    "        self.output_dir = 'output'\n",
    "        self.model_type = 'gpt2'\n",
    "        self.model_name_or_path = 'microsoft/DialoGPT-small'\n",
    "        self.config_name = 'microsoft/DialoGPT-small'\n",
    "        self.tokenizer_name = 'microsoft/DialoGPT-small'\n",
    "        self.cache_dir = 'cached'\n",
    "        self.block_size = 512\n",
    "        self.do_train = True\n",
    "        self.do_eval = True\n",
    "        self.evaluate_during_training = False\n",
    "        self.per_gpu_train_batch_size = 4\n",
    "        self.per_gpu_eval_batch_size = 4\n",
    "        self.gradient_accumulation_steps = 1\n",
    "        self.learning_rate = 5e-5\n",
    "        self.weight_decay = 0.0\n",
    "        self.adam_epsilon = 1e-8\n",
    "        self.max_grad_norm = 1.0\n",
    "        self.num_train_epochs = 3\n",
    "        self.max_steps = -1\n",
    "        self.warmup_steps = 0\n",
    "        self.logging_steps = 1000\n",
    "        self.save_steps = 3500\n",
    "        self.save_total_limit = None\n",
    "        self.eval_all_checkpoints = False\n",
    "        self.no_cuda = False\n",
    "        self.overwrite_output_dir = True\n",
    "        self.overwrite_cache = True\n",
    "        self.should_continue = False\n",
    "        self.seed = 42\n",
    "        self.local_rank = -1\n",
    "        self.fp16 = False\n",
    "        self.fp16_opt_level = 'O1'\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "df_contoh = pd.read_csv('./data/final_es_conv.csv')\n",
    "df = pd.DataFrame(joblib.load('./data/sub-indo_lengkap.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['percakapan'] =df['percakapan'].apply(lambda x: ' '.join(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>percakapan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>srt/Fallen.2016.720p.BRRiP.850MB.ShAaNiG.srt</td>\n",
       "      <td>oleh budak bangka tidak untuk para penjual fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>srt/James Bond - For Your Eyes Only (1981).srt</td>\n",
       "      <td>artficial www facebook com movieartficial tuan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>srt/Layer.Cake.2004.720p.BrRip.x264.YIFY.srt</td>\n",
       "      <td>saat aku lahir dunia adalah tempat yang jauh l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>srt/Once.Upon.A.Time.In.London.2019.720p.WEBRi...</td>\n",
       "      <td>diterjemahkan ke bahasa indonesia oleh ndaelic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>srt/King.Arthur.Excalibur.Rising.2017.1080p.Bl...</td>\n",
       "      <td>subtitles by explosiveskull font color gold se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  judul  \\\n",
       "2008       srt/Fallen.2016.720p.BRRiP.850MB.ShAaNiG.srt   \n",
       "2095     srt/James Bond - For Your Eyes Only (1981).srt   \n",
       "998        srt/Layer.Cake.2004.720p.BrRip.x264.YIFY.srt   \n",
       "2254  srt/Once.Upon.A.Time.In.London.2019.720p.WEBRi...   \n",
       "1171  srt/King.Arthur.Excalibur.Rising.2017.1080p.Bl...   \n",
       "\n",
       "                                             percakapan  \n",
       "2008  oleh budak bangka tidak untuk para penjual fil...  \n",
       "2095  artficial www facebook com movieartficial tuan...  \n",
       "998   saat aku lahir dunia adalah tempat yang jauh l...  \n",
       "2254  diterjemahkan ke bahasa indonesia oleh ndaelic...  \n",
       "1171  subtitles by explosiveskull font color gold se...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "trn_df, val_df = train_test_split(df, test_size = 0.2)\n",
    "trn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from collections import Counter\n",
    "from statistics import mean, median, stdev\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "def get_counter_and_lens(data, tokenizer):\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    toks = [tokenizer.tokenize(x) for x in data]\n",
    "    \n",
    "    return list(map(len, toks)), Counter(flatten(toks)), Counter(' '.join(data).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "def plot_counts(counts, top_k = 30):\n",
    "    labels, values = zip(*counts.most_common()[:top_k])\n",
    "\n",
    "    indexes = np.arange(len(labels))\n",
    "    width = 1\n",
    "    plt.figure(num=None, figsize=(22, 4), dpi=60, facecolor='w', edgecolor='k')\n",
    "    plt.bar(indexes, values, width)\n",
    "    plt.xticks(indexes + width * 0.5, labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path, cache_dir=args.cache_dir)\n",
    "lens, tok_cnt, word_cnt = get_counter_and_lens(df['percakapan'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABB4AAADaCAYAAAABkIGCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAJOgAACToB8GSSSgAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de1TUdf7H8RcIWh5XkVLDFrOysvIumlxGRl2MMG0LB7PWoptk6mpejlraMfO2cbYsc410vWSWMVbrKqZCCiJYSYXrZdejpmdRW00lMPPCD+f3h8c5IjAozGeGwefjH2U+w/f9/n7n8v3yms/3O34Oh8MhAAAAAAAAA/y93QAAAAAAAKi7CB4AAAAAAIAxBA8AAAAAAMAYggcAAAAAAGAMwQMAAAAAADDGY8FDUVGRunfvrkaNGmnnzp2V3u/cuXNKSkpS79699cgjj3iqPQAAAAAAYECApwo1bNhQaWlpGj9+vMv7zZ07V3FxcYQOAAAAAADUAR6b8RAYGKhmzZqVuW3JkiWyWCyKiIjQxo0bJUnr1q3Tli1bZLValZKS4qn2AAAAAACAAV67xsOJEye0YsUKbd68Wenp6Zo2bZokqaCgQN27d1dGRoY+/vhjHTp0yFstAgAAAACAGvLYqRZX2r9/v3bt2qVevXpJkn7++WdJUlBQkHr37q2AgABFRERoz549+v3vf++tNgEAAAAAQA14bcbDHXfcoQ4dOmjTpk3KzMxUfn6+JCkyMtL5/+3bt+v222/3VosAAAAAAKCG/BwOh8NTxeLi4pSfn6/bbrtNSUlJqlevnhYsWKB69eqpffv2evfdd3X06FElJiaquLhYMTExmjp1qqfaAwAAAAAAbubR4AEAAAAAAFxfvHaqBQAAAAAAqPs8cnHJrl276s477/REKQAAAAAA4AX79+/Xd999V+52jwQPd955p1JTUz1RCgAAAAAAeEFCQkKFt3OqBQAAAAAAMIbgAQAAAAAAGEPwAAAAAAAAjCF4AAAAAAAAxhA8AAAAAAAAYwgeAAAAAACAMQQPAAAAAADAmABXg0VFRYqJidHu3bv19ddfq127dmXGV6xYoQ8++EAXLlzQrFmzFB4ebrRZb2g9Mc1rtQ/O7ue12gAAAAAAuIPL4KFhw4ZKS0vT+PHjy40dOXJEq1at0ldffSU/Pz9jDQIAAAAAAN/l8lSLwMBANWvWrMKxdevWqUGDBoqJidGQIUP066+/GmkQAAAAAAD4rmpf4+Ho0aM6fvy40tPTFR4ervfee8+dfQEAAAAAgDrA5akWrgQFBalXr17y8/NTnz59NH369DLjdrtddrtdklRQUFCzLgEAAAAAgE+q9oyHyMhI5efnS5Ly8/N1xx13lBm32WxKTU1VamqqQkNDa9YlAAAAAADwSVXOeIiLi1N+fr727NmjpKQkbd26VSkpKerQoYNCQ0NltVrVoEEDLV++3BP9AgAAAAAAH1Jl8LB27doyPycmJjr/P3PmTLc3BAAAAAAA6o5qn2oBAAAAAABQFYIHAAAAAABgDMEDAAAAAAAwhuABAAAAAAAYQ/AAAAAAAACMIXgAAAAAAADGEDwAAAAAAABjArzdACrXemKa12ofnN3Pa7UBAAAAAHUHMx4AAAAAAIAxBA8AAAAAAMAYggcAAAAAAGAMwQMAAAAAADCG4AEAAAAAABhD8AAAAAAAAIxxGTwUFRWpe/fuatSokXbu3FnhfWbPnq2wsDAjzQEAAAAAAN/mMnho2LCh0tLSNHDgwArHT506pR07dhhpDAAAAAAA+D6XwUNgYKCaNWtW6fg777yjESNGuL0pAAAAAABQNwRU9xeLioq0Y8cOTZ48ucJxu90uu90uSSooKKhuGQAAAAAA4MOqHTzMmTNHI0eOrHTcZrPJZrNJkhISEqpbBgAAAAAA+LBqBw/79u3T1q1bJUl79+7VjBkz9Oqrr7qtMQAAAAAA4PuqDB7i4uKUn5+vPXv2KCkpSVu3blVKSoqWLVvmvE9YWBihAwAAAAAAKKfK4GHt2rVlfk5MTCx3n7y8PLc1BAAAAAAA6g6X32oBAAAAAABQEwQPAAAAAADAGIIHAAAAAABgDMEDAAAAAAAwhuABAAAAAAAYQ/AAAAAAAACMIXgAAAAAAADGEDwAAAAAAABjCB4AAAAAAIAxBA8AAAAAAMAYggcAAAAAAGAMwQMAAAAAADCG4AEAAAAAABjjMngoKipS9+7d1ahRI+3cubPM2OrVq/XAAw8oKipKo0aNMtokAAAAAADwTS6Dh4YNGyotLU0DBw4sN9axY0fl5ORoy5YtOnbsmPLy8ow1CQAAAAAAfFOAq8HAwEA1a9aswrFWrVo5/1+/fn35+3PWBgAAAAAAKMtl8HA1tm3bpmPHjqlLly5lbrfb7bLb7ZKkgoKCmpYBAAAAAAA+qEbBw6FDhzR69Gh98cUX5cZsNptsNpskKSEhoSZlAAAAAACAj6r2+RGnTp3S448/rpSUFDVv3tydPQEAAAAAgDqiyuAhLi5OGzZs0AsvvKAlS5YoKSlJkjRnzhwdOHBAI0aMkNVqVVZWlvFmAQAAAACAb6nyVIu1a9eW+TkxMVGSNGXKFE2ZMsVIUwAAAAAAoG7gqygAAAAAAIAxBA8AAAAAAMAYggcAAAAAAGAMwQMAAAAAADCG4AEAAAAAABhD8AAAAAAAAIwheAAAAAAAAMYQPAAAAAAAAGMIHgAAAAAAgDEEDwAAAAAAwJgAbzeA2qn1xDSv1T44u5/XagMAAAAA3IsZDwAAAAAAwBiCBwAAAAAAYIzL4KGoqEjdu3dXo0aNtHPnzjJjpaWlevbZZ2WxWDR69GijTQIAAAAAAN/kMnho2LCh0tLSNHDgwHJja9asUcuWLZWdna3Tp09r69atxpoEAAAAAAC+yWXwEBgYqGbNmlU4lpubq759+0qSYmNjlZOT4/7uAAAAAACAT6v2t1oUFhaqcePGkqQmTZro5MmTZcbtdrvsdrskqaCgoAYtAgAAAAAAX1Xt4CEoKEjFxcWSLl4LIjg4uMy4zWaTzWaTJCUkJNSgRQAAAAAA4Kuq/a0WERERysjIkCStX79ekZGRbmsKAAAAAADUDVUGD3FxcdqwYYNeeOEFLVmyRElJSZKkhx9+WP/9739lsVh0ww03KDw83HizAAAAAADAt1R5qsXatWvL/JyYmHjxFwMCtGTJEhM9AQAAAACAOqLa13gATGk9Mc1rtQ/O7ue12gAAAABQF1X7Gg8AAAAAAABVIXgAAAAAAADGEDwAAAAAAABjuMYDcBmuLwEAAAAA7kXwANQShB4AAAAA6iJOtQAAAAAAAMYQPAAAAAAAAGM41QIAp3kAAAAAMIYZDwAAAAAAwBiCBwAAAAAAYAzBAwAAAAAAMIbgAQAAAAAAGFNl8DBhwgRZLBYNGTJEJSUlztvPnDmj/v37Kzo6Wn369NHRo0eNNgoAAAAAAHyPy2+12L59uw4fPqzs7GzNmDFDK1eu1ODBgyVJX375pdq1a6dZs2Zp2bJl+vvf/65XXnnFI00DqDv4Rg0AAACgbnM54yE3N1d9+/aVJMXGxionJ8c51qZNG50+fVqSVFhYqJtvvtlgmwAAAAAAwBe5nPFQWFiokJAQSVKTJk108uRJ59hdd92l3bt36/7775fD4dC3335b5nftdrvsdrskqaCgwN19AwAAAAAAH+ByxkNQUJCKi4slSUVFRQoODnaOLV26VFFRUdq1a5emTZumN954o8zv2mw2paamKjU1VaGhoQZaBwAAAAAAtZ3L4CEiIkIZGRmSpPXr1ysyMtI55nA4nKdX3HzzzSoqKjLYJgAAAAAA8EUug4dOnTqpRYsWslgs2rVrl+Lj45WUlCRJeuKJJ7RmzRpZrVZNmTJFY8aM8UjDAAAAAADAd7i8xoMkJScnl/k5JSVF0sVrPqxbt85MVwAAAAAAoE5wOeMBAAAAAACgJggeAAAAAACAMVWeagEAdVXriWleq31wdj+v1QYAAAA8ieABALzAm6GHNxG4AAAAXH841QIAAAAAABhD8AAAAAAAAIwheAAAAAAAAMYQPAAAAAAAAGMIHgAAAAAAgDF8qwUAwGP4ClMAAIDrDzMeAAAAAACAMQQPAAAAAADAGIIHAAAAAABgTJXXeJgwYYJyc3PVunVrLVq0SIGBgc6xFStW6IMPPtCFCxc0a9YshYeHG20WAIDq4voSAAAA3uFyxsP27dt1+PBhZWdnq23btlq5cqVz7MiRI1q1apW++uorZWZmEjoAAAAAAIByXM54yM3NVd++fSVJsbGxWrx4sQYPHixJWrdunRo0aKCYmBiFhIRo/vz5atSokfmOAQDwMcy2AAAA1zOXwUNhYaFCQkIkSU2aNNHJkyedY0ePHtXx48eVnp6u+fPn67333tPEiROd43a7XXa7XZJUUFBgoncAAFAFQg8AAOBtLk+1CAoKUnFxsSSpqKhIwcHBZcZ69eolPz8/9enTR7t27SrzuzabTampqUpNTVVoaKiB1gEAAAAAQG3ncsZDRESE3nrrLT311FNav369IiMjnWORkZFKTk6WJOXn5+uOO+4w2ykAAPApzLYAAABSFTMeOnXqpBYtWshisWjXrl2Kj49XUlKSJKlDhw4KDQ2V1WrVokWLNHLkSI80DAAAAAAAfEeVX6d5aVbDJSkpKc7/z5w50/0dAQAAAACAOsPljAcAAAAAAICaIHgAAAAAAADGVHmqBQAAgK/hwpYAANQeBA8AAABuROgBAEBZBA8AAAB1BKEHAKA24hoPAAAAAADAGIIHAAAAAABgDMEDAAAAAAAwhuABAAAAAAAYQ/AAAAAAAACMIXgAAAAAAADG8HWaAAAAqDFvfpWnN/E1ogBQNYIHAAAAoJq8GbgQegDwFVWeajFhwgRZLBYNGTJEJSUl5cZnz56tsLAwI80BAAAAAADf5jJ42L59uw4fPqzs7Gy1bdtWK1euLDN+6tQp7dixw2iDAAAAAADAd7k81SI3N1d9+/aVJMXGxmrx4sUaPHiwc/ydd97RiBEjNHLkSLNdAgAAACiD62oA8BUug4fCwkKFhIRIkpo0aaKTJ086x4qKirRjxw5Nnjy5wt+12+2y2+2SpIKCAnf1CwAAAAAAfIjL4CEoKEjFxcWSLgYNwcHBzrE5c+a4nOlgs9lks9kkSQkJCe7oFQAAAAAA+BiX13iIiIhQRkaGJGn9+vWKjIx0ju3bt0/Tp09XbGys9u7dqxkzZpjtFAAAAAAA+ByXMx46deqkFi1ayGKxqFWrVho3bpySkpKUkpKiZcuWOe8XFhamV1991XizAAAAAADAt7gMHiQpOTm5zM8pKSnl7pOXl+e+jgAAAACgEt68qCYXtgSqx+WpFgAAAAAAADVB8AAAAAAAAIwheAAAAAAAAMYQPAAAAAAAAGOqvLgkAAAAAMC7F7b0Ji6qiZpixgMAAAAAADCGGQ8AAAAAgEox0wM1xYwHAAAAAABgDDMeAAAAAAC4gjdnetS12RbMeAAAAAAAAMYQPAAAAAAAAGMIHgAAAAAAgDEEDwAAAAAAwJgqg4cJEybIYrFoyJAhKikpcd6+evVqPfDAA4qKitKoUaOMNgkAAAAAAHyTy+Bh+/btOnz4sLKzs9W2bVutXLnSOdaxY0fl5ORoy5YtOnbsmPLy8ow3CwAAAAAAfIvL4CE3N1d9+/aVJMXGxionJ8c51qpVKwUEXPw2zvr168vfn7M2AAAAAABAWQGuBgsLCxUSEiJJatKkiU6ePFnuPtu2bdOxY8fUpUuXMrfb7XbZ7XZJUkFBgbv6BQAAAAAAPsRl8BAUFKTi4mJJUlFRkYKDg8uMHzp0SKNHj9YXX3xR7ndtNptsNpskKSEhwV39AgAAAAAAH+Ly/IiIiAhlZGRIktavX6/IyEjn2KlTp/T4448rJSVFzZs3N9slAAAAAADwSS6Dh06dOqlFixayWCzatWuX4uPjlZSUJEmaM2eODhw4oBEjRshqtSorK8sjDQMAAAAAAN/h8lQLSUpOTi7zc0pKiiRpypQpmjJlipmuAAAAAABAncBXUQAAAAAAAGMIHgAAAAAAgDEEDwAAAAAAwBiCBwAAAAAAYAzBAwAAAAAAMIbgAQAAAAAAGEPwAAAAAAAAjCF4AAAAAAAAxhA8AAAAAAAAYwgeAAAAAACAMQQPAAAAAADAGIIHAAAAAABgDMEDAAAAAAAwpsrgYcKECbJYLBoyZIhKSkqct5eWlurZZ5+VxWLR6NGjjTYJAAAAAAB8k8vgYfv27Tp8+LCys7PVtm1brVy50jm2Zs0atWzZUtnZ2Tp9+rS2bt1qvFkAAAAAAOBbXAYPubm56tu3ryQpNjZWOTk5VzUGAAAAAAAgSQGuBgsLCxUSEiJJatKkiU6ePFlmrHHjxhWOSZLdbpfdbpck5eXlKSEhwa2Ne0p3L9YuKChQaGgotalNbWpTm9rUpja1qU1talP7OqodHj7da7VrYv/+/RUPOFyYN2+eY+nSpQ6Hw+HIy8tzDB8+3Dk2fvx4R1ZWlsPhcDhWrlzpSE5OdrUoVIPNZqM2talNbWpTm9rUpja1qU1talPbp7k81SIiIkIZGRmSpPXr1ysyMvKqxgAAAAAAACSp3tSpU6dWNnjLLbcoNzdXb7zxhs6fP69JkybppZdeUv/+/dWmTRstW7ZMf/3rXxUaGqqhQ4d6sO3rx/33309talOb2tSmNrWpTW1qU5va1Ka2z/JzOBwObzcBAAAAAADqJpenWgAAAAAAANQEwYOXPPPMM95uoZza2FNdxzZ3P7Yp4P3Xgbfre4vJ9b5et2lt5Y3HozY8B2pDD55Um9a3NvXiCdfT+l4v60rw4GE5OTnq1auXDhw4oOjoaH322Wdav369unXrpuTk5KtezsGDB7VhwwZjPVmtVv36669uWf61OHjwoAYOHOjxup5W0TZHzdRkm4aFhRnsrDxPPs8zMzM1btw4j9SqSn5+vubPn+/tNuq0ql4HAwcO1MGDBz1avzr7uGvlcDj0yCOPqFevXurXr5969eqln3/+2Xnbzz//bKy2VPF6L1myROfPnzey7Nrql19+UWpqqrHl14b3M28cM9WG50Bt6OFypvfbtenYuKJeRo8erTNnzhivfWm/7cnjJFfrm5+fr2+//dZ4D546Xqlq37FkyRJt3bq1zO/8+uuvslqtxnszwsvfqnFdOX78uKNDhw6OI0eOOBwOh+P8+fOO3Nxcx9ChQx3ff//9NS1r06ZNjrFjxxrrKTo62nHq1KkaL/9aHThwwBEfH+/xup5U2TZH9dV0m3bt2vWq7ldaWlqt/q7kyee5u94rUPtdzesgPj7eceDAAY/Wr84+7lodOXLEMWDAAOe/l99mmsn9qK/tL0y/t3n7/cwbx0y14TlQG3q40tXut6ujNh0b15Ztb3J7X66q9V28eLFj7ty5HunFtOo+z06dOuWIjo72UJfuxYwHD1q7dq0effRRhYSESJICAwN15swZrVq1SkOHDtU///lPbdq0ST169FCPHj304YcfSpISExP14osvKiYmRn/84x/lcDg0f/58ffrpp7JarTp58qRbewoPD3eOb9iwQYMGDdK5c+dqsOaVO3r0qHr16iWLxaKBAweqtLRUknThwgUNGzbMuQ1M1du/f78iIyM1aNAgtW/fXhs3bpR0cb07d+4sm82mnj17uvUTwsq2eXJysqxWq7p06aL09HS31XPl8k+Pdu7cqcTERI/UlSp/7Kujsm367bffKioqSlar1flp69ixYxUVFaXevXuXe1x37NihqKgoRUZGatasWZKkqVOnKjExUXFxcfrXv/7ltnX96aefyj3vTDp79qwSEhJ06623aufOnZKkcePGKTMz03jtSzz5aeXVvtY9VfvSDBeTn1RU9jrIyMhQly5d9Nhjj+nw4cNGaldW/8p9nCmjRo1Sbm6uhg8frtzcXD322GPO2x577DFjdaWK11u6+InZQw89pLfeesutyw4PD5fVatWYMWPUo0cPTZ06VSNHjlRYWJjmzJkjSfrxxx/14IMPymq16uWXX5Z08ZOz+Ph49e/fX926ddNPP/1Uk9WWVP65Pm/ePGVlZclqtWr37t01Xn5lLr2fpaenKzo6Wt26ddPs2bMlmVnPS1wdM02aNEk9e/bUqFGj3FbPVc1nnnlGFotFVqtVBw8e1NmzZ/WnP/1JvXv31oABA1RcXGy0hzZt2qhfv37O+/Tp08etNS/n6lhl6dKleumll+Rw47Xyr+XYeObMmYqOjlbPnj21Y8cOt/VQVS+emn1x5X7bxPa+XFXrO3/+fL3zzjvq27evkfqXXFrvMWPGKDo6Wt27d1d+fr5ba1zNvmPq1Klas2aNJGnkyJGKjo7WpEmT3NqHJxE8eNCRI0ecT66NGzfKarVqzpw5io2N1eLFizVgwABNmjRJa9asUXZ2tt59913nNKqIiAilp6erQYMG2rFjh4YNG6ZBgwYpMzNTwcHBbu1pwIABkqTVq1dr6dKl+uijj9SgQYMarn3FmjZtqvT0dGVnZ+vWW2/Vxo0bVVpaqueff15Wq1VPPfWU8XrHjx/X8uXLlZqaqvfee0+S9Nprr+mrr77SRx99pIKCArf2UNk2Hz58uDIzM7Vu3TpNnz7drTVro4oei+qqbJu+/PLL+uSTT5SZmamxY8cqLy9Phw8f1pYtW/T6669r2rRpZZbzyiuvaMGCBdqyZYs2bdrkDCZCQ0O1du1aderUyW3rWtHzzpTffvtNgwcP1vDhwxUTE2O0Vm3hzW3uzuf2tajsdTB58mRlZGTok08+0ZEjRzxa/8p9nClvvvmmoqOj9dZbbyk6Olqff/6587bPP//cWF2p4vWeNWuWOnXqpC+//FJjxoxx67Ivbcf4+Hjl5uZq4cKFeu655/T1119r2bJlkqSJEyfqb3/7mzIzM3X27Fnl5eVJkpo0aaLVq1fr2Wefld1ur8lqSyr/XL/77rsVHR2tzMxM3XfffTVefkUufz+LjIxUVlaWvvnmG3322WfOYyZ3r+clrh6P/v37a/PmzTp69Ki+//57ozUfeugh7dmzR5s3b1ZmZqZatWqlhQsXqnfv3tq4caOefPJJffDBB0Z7eO6551S/fn399NNP+vHHH9W8eXM1btzYbTWvxvvvv68ffvhB8+bNk5+fn9uWe7XHxnv37tWePXuUlZWlFStWaPLkyW7r4Wp68TRT2/tyVa3vsGHDNGrUKLedbl6V6dOnKysrSykpKW4/XfBa9h15eXk6ceKEsrKyygR+vibA2w1cT1q2bKm9e/dKknr37q3evXsrLCysTHBQWlqqm2++WZLUpk0b50Fi586dJV38A6iwsNB4T40aNdLkyZO1ceNGZwJnwokTJzRs2DAVFhbqyJEjCg4O1jfffKNOnTpp0KBBHqnXrl07BQQElNm2paWlzselXbt2bu2hsm2+bNkyLV++XP7+/m79hMaVy3ccptLrylz5WHTp0qXay6psm/r5+Sk0NFSS5O/vr3379qlbt26SpG7duumVV14ps5z//e9/uvfeeyVJXbp00f79+533rYmrfd6ZsmrVKg0YMEDR0dFasmSJ83ZPP+ae5M1t7uq5bXKbu3odXHo/69Chg8fr1yQc9wWu9qMml92hQwf5+/vrlltuUceOHeXn5+fcX//nP//Rc889J0k6deqUHnzwQUlljyW+++67GvdX0evMtMvfz7Kzs/X666+rpKREBw8e1LFjxyS5fz0vcfV4dO3aVdLF/cXevXtrtE+7mpovv/yyhgwZoptuukkzZszQ7t27tW3bNn344YcqKSmRxWJxS31XPUyaNEmffPKJTp8+rSeffNJt9a5U0bHKmTNn9Pbbb2vbtm1u/yP4ao+Nd+/erdzcXOcstnr16rm1j6p68SST2/tytWV9L0lOTlZGRoYkKSDAvX82X8u67tu3r8x7jK9ixoMHxcXF6YsvvnCGCf/3f/9X7j7+/v46fvy4SkpKtHfvXrVs2VJS+TfdwMDAGk1Nv5qeUlNT9fTTTzt35CZ8/PHHevjhh5WVlaXY2FjddtttioiI0IMPPqixY8d6pF5FO7R69eqpsLBQ58+f165du9zaQ2XbfO7cudq0aZM+/fRTj/1B2LRpUx06dEiStH37do/UvOTKx6Im61zZNm3QoIFzavmFCxfUpk0bbdu2TZK0bds23XXXXWWW06JFC/373/+Ww+HQ999/rzvvvFPSxddlTVzt886UwYMH64YbbtC7775b5jGv7qkjvsCb2/zK2r/88ovzeWjydVbZ6+DS+9m5c+eMTAWuqn5dV9l6u2M/7WqbXv58vvIPgXvuuUdLly5VZmam8vLy9PDDD5e7nzteA1c+1wMCAtxybOLK5e9nb775pt5//31t2rRJt956q3OdTL3WXT0eP/zwg6SLn0y2adPGaM3S0lIlJCToo48+UosWLfT555+rbdu2+vOf/6zMzEzl5OTojTfeMNqDdHGWR1pamtLT0xUbG+u2eleq6Fjlxhtv1KJFizRo0CD99ttvbq13tcfGbdu2dc7wuTRj1d1qy/uqye19uarW111//1yNEydOOGd0zZkzx+3HDdey72jTpk2Z9xhfxYwHD7rpppv0/vvv64knnpCfn5/8/f01evRoZ5ImSTNnzlS/fv3k5+enESNG6MYbb6xwWe3bt9ekSZNks9m0YMECBQUFubWnhQsX6p577tHcuXM1ePBgrVy5Uk2bNq1WDVf69OmjIUOGaPXq1WXWddSoUZo5c6Zee+21ctPhTdS70rRp09SnTx/dfvvtuuWWW9w666Oybb5lyxZFRUWpR48eHkt227dvr99++00xMTFun9lRlat9LK5GZdv07rvvVkJCggIDA9WvXz+NHz9eISEhioqKUkBAgBYvXlxmOTNmzNDzzz8vh8Ohfv36qXXr1jXq6xJ3rmt1vf3223rxxRd13333acKECVqwYIEaNmzolV48wZvb/MraXbt2VefOnWWxWBQdHW2sbmWvg+bNm6tPnz5q3bq1WrVq5fH6l+/j6qLK1ruwsFAJCQmKj4/X0KFD3brshQsXuvy9v/zlL3rxxRd19uxZ1atXT4sWLapW/fy/uOsAAAGISURBVKpc+Vzv3Lmzzpw5o4EDB2rWrFnlwl13ufR+9uijj+rRRx9V+/bt9bvf/c5Ircu5ejy+/PJLTZs2TR07dnR+Mmmq5tixY/WHP/xBfn5+8vPz0/LlyxUcHKyhQ4c692tjx45125Tsyta7fv36atu2rfz9/d3+afDlKjtWiYyM1Lhx4/T444/Lbre77bTgazk2vuuuuxQdHS1/f3/FxMSUm0lpshdPM7W9L1fV+oaHh+upp57SN998o48//tjt9S/XtGlTBQcHy2q1qkePHm5f/tXsOy4JCwtT48aN1bNnT5+e8eDnqMtzbYFqKikpUWBgoM6dO6du3brphx9+MDKFDgAAwFeNHDlSTz/9tMe/lvp6FxERoc2bNxsNfAB349kKVOAf//iH5s2bp+LiYo0ePZrQAQAA4DIvvfSSioqKCB08bMaMGbr33nsJHeBzmPEAAAAAAACM4eKSAAAAAADAGIIHAAAAAABgDMEDAAAAAAAwhuABAAAAAAAYQ/AAAAAAAACM+X9Pv5ZqwvusmQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1320x240 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1320x240 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_counts(tok_cnt, top_k = 30)\n",
    "plot_counts(word_cnt, top_k = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 16015.851506456242, Median: 15081.5, Standard Deviation: 6760.388138999562, 90th Percentile: 52455.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse\n",
    "def plot_hist(lens, n_bins = 50):\n",
    "    n, bins, patches = plt.hist(lens, n_bins, facecolor='blue', alpha=0.9)\n",
    "    plt.show()\n",
    "print(f'Mean: {mean(lens)}, Median: {median(lens)}, Standard Deviation: {stdev(lens)}, 90th Percentile: {np.percentile(lens, 100)}')\n",
    "plot_hist(lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training and dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "def construct_conv(row, tokenizer, eos = True):\n",
    "    # from: https://stackoverflow.com/questions/952914/how-to-make-a-flat-list-out-of-list-of-lists\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    conv = list(reversed([tokenizer.encode(x) + [tokenizer.eos_token_id] for x in row]))\n",
    "    conv = flatten(conv)\n",
    "    return conv\n",
    "\n",
    "class ConversationDataset(Dataset):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer, args, df, block_size=512):\n",
    "\n",
    "        block_size = block_size - (tokenizer.max_len - tokenizer.max_len_single_sentence)\n",
    "\n",
    "        directory = args.cache_dir\n",
    "        cached_features_file = os.path.join(\n",
    "            directory, args.model_type + \"_cached_lm_\" + str(block_size)\n",
    "        )\n",
    "\n",
    "        if os.path.exists(cached_features_file) and not args.overwrite_cache:\n",
    "            logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "            with open(cached_features_file, \"rb\") as handle:\n",
    "                self.examples = pickle.load(handle)\n",
    "        else:\n",
    "            logger.info(\"Creating features from dataset file at %s\", directory)\n",
    "\n",
    "            self.examples = []\n",
    "            for _, row in df.iterrows():\n",
    "                conv = construct_conv(row, tokenizer)\n",
    "                if len(conv) > block_size: continue\n",
    "                self.examples.append(conv)\n",
    "\n",
    "            # Note that we are loosing the last truncated example here for the sake of simplicity (no padding)\n",
    "            # If your dataset is small, first you should loook for a bigger one :-) and second you\n",
    "            # can change this behavior by adding (model specific) padding.\n",
    "\n",
    "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "            with open(cached_features_file, \"wb\") as handle:\n",
    "                pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return torch.tensor(self.examples[item], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# Cacheing and storing of data/checkpoints\n",
    "\n",
    "def load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False):\n",
    "    return ConversationDataset(tokenizer, args, df_val if evaluate else df_trn)\n",
    "\n",
    "\n",
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "\n",
    "def _sorted_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> List[str]:\n",
    "    ordering_and_checkpoint_path = []\n",
    "\n",
    "    glob_checkpoints = glob.glob(os.path.join(args.output_dir, \"{}-*\".format(checkpoint_prefix)))\n",
    "\n",
    "    for path in glob_checkpoints:\n",
    "        if use_mtime:\n",
    "            ordering_and_checkpoint_path.append((os.path.getmtime(path), path))\n",
    "        else:\n",
    "            regex_match = re.match(\".*{}-([0-9]+)\".format(checkpoint_prefix), path)\n",
    "            if regex_match and regex_match.groups():\n",
    "                ordering_and_checkpoint_path.append((int(regex_match.groups()[0]), path))\n",
    "\n",
    "    checkpoints_sorted = sorted(ordering_and_checkpoint_path)\n",
    "    checkpoints_sorted = [checkpoint[1] for checkpoint in checkpoints_sorted]\n",
    "    return checkpoints_sorted\n",
    "\n",
    "\n",
    "def _rotate_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> None:\n",
    "    if not args.save_total_limit:\n",
    "        return\n",
    "    if args.save_total_limit <= 0:\n",
    "        return\n",
    "\n",
    "    # Check if we should delete older checkpoint(s)\n",
    "    checkpoints_sorted = _sorted_checkpoints(args, checkpoint_prefix, use_mtime)\n",
    "    if len(checkpoints_sorted) <= args.save_total_limit:\n",
    "        return\n",
    "\n",
    "    number_of_checkpoints_to_delete = max(0, len(checkpoints_sorted) - args.save_total_limit)\n",
    "    checkpoints_to_be_deleted = checkpoints_sorted[:number_of_checkpoints_to_delete]\n",
    "    for checkpoint in checkpoints_to_be_deleted:\n",
    "        logger.info(\"Deleting older checkpoint [{}] due to args.save_total_limit\".format(checkpoint))\n",
    "        shutil.rmtree(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "# Training of model\n",
    "\n",
    "def train(args, train_dataset, model: PreTrainedModel, tokenizer: PreTrainedTokenizer) -> Tuple[int, float]:\n",
    "    \"\"\" Train the model \"\"\"\n",
    "    if args.local_rank in [-1, 0]:\n",
    "        tb_writer = SummaryWriter()\n",
    "\n",
    "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
    "\n",
    "    def collate(examples: List[torch.Tensor]):\n",
    "        if tokenizer._pad_token is None:\n",
    "            return pad_sequence(examples, batch_first=True)\n",
    "        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, collate_fn=collate, drop_last = True\n",
    "    )\n",
    "\n",
    "    if args.max_steps > 0:\n",
    "        t_total = args.max_steps\n",
    "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
    "    else:\n",
    "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "\n",
    "    model = model.module if hasattr(model, \"module\") else model  # Take care of distributed/parallel training\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    # add_special_tokens_(model, tokenizer)\n",
    "\n",
    "\n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
    "    )\n",
    "\n",
    "    # Check if saved optimizer or scheduler states exist\n",
    "    if (\n",
    "        args.model_name_or_path\n",
    "        and os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\"))\n",
    "        and os.path.isfile(os.path.join(args.model_name_or_path, \"scheduler.pt\"))\n",
    "    ):\n",
    "        # Load in optimizer and scheduler states\n",
    "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
    "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
    "\n",
    "    if args.fp16:\n",
    "        try:\n",
    "            from apex import amp\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
    "\n",
    "    # multi-gpu training (should be after apex fp16 initialization)\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Distributed training (should be after apex fp16 initialization)\n",
    "    if args.local_rank != -1:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(\n",
    "            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True\n",
    "        )\n",
    "\n",
    "    # Train!\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
    "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
    "    logger.info(\n",
    "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
    "        args.train_batch_size\n",
    "        * args.gradient_accumulation_steps\n",
    "        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n",
    "    )\n",
    "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    epochs_trained = 0\n",
    "    steps_trained_in_current_epoch = 0\n",
    "    # Check if continuing training from a checkpoint\n",
    "    if args.model_name_or_path and os.path.exists(args.model_name_or_path):\n",
    "        try:\n",
    "            # set global_step to gobal_step of last saved checkpoint from model path\n",
    "            checkpoint_suffix = args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0]\n",
    "            global_step = int(checkpoint_suffix)\n",
    "            epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n",
    "            steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n",
    "\n",
    "            logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
    "            logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n",
    "            logger.info(\"  Continuing training from global step %d\", global_step)\n",
    "            logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n",
    "        except ValueError:\n",
    "            logger.info(\"  Starting fine-tuning.\")\n",
    "\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(\n",
    "        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0]\n",
    "    )\n",
    "    set_seed(args)  # Added here for reproducibility\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "\n",
    "            # Skip past any already trained steps if resuming training\n",
    "            if steps_trained_in_current_epoch > 0:\n",
    "                steps_trained_in_current_epoch -= 1\n",
    "                continue\n",
    "\n",
    "            inputs, labels = (batch, batch)\n",
    "            if inputs.shape[1] > 1024: continue\n",
    "            inputs = inputs.to(args.device)\n",
    "            labels = labels.to(args.device)\n",
    "            model.train()\n",
    "            outputs = model(inputs, labels=labels)\n",
    "            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
    "\n",
    "            if args.n_gpu > 1:\n",
    "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
    "            if args.gradient_accumulation_steps > 1:\n",
    "                loss = loss / args.gradient_accumulation_steps\n",
    "\n",
    "            if args.fp16:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "                if args.fp16:\n",
    "                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
    "                else:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
    "                    # Log metrics\n",
    "                    if (\n",
    "                        args.local_rank == -1 and args.evaluate_during_training\n",
    "                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n",
    "                        results = evaluate(args, model, tokenizer)\n",
    "                        for key, value in results.items():\n",
    "                            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n",
    "                    tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n",
    "                    tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n",
    "                    logging_loss = tr_loss\n",
    "\n",
    "                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n",
    "                    checkpoint_prefix = \"checkpoint\"\n",
    "                    # Save model checkpoint\n",
    "                    output_dir = os.path.join(args.output_dir, \"{}-{}\".format(checkpoint_prefix, global_step))\n",
    "                    os.makedirs(output_dir, exist_ok=True)\n",
    "                    model_to_save = (\n",
    "                        model.module if hasattr(model, \"module\") else model\n",
    "                    )  # Take care of distributed/parallel training\n",
    "                    model_to_save.save_pretrained(output_dir)\n",
    "                    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
    "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "\n",
    "                    _rotate_checkpoints(args, checkpoint_prefix)\n",
    "\n",
    "                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
    "                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
    "                    logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n",
    "\n",
    "            if args.max_steps > 0 and global_step > args.max_steps:\n",
    "                epoch_iterator.close()\n",
    "                break\n",
    "        if args.max_steps > 0 and global_step > args.max_steps:\n",
    "            train_iterator.close()\n",
    "            break\n",
    "\n",
    "    if args.local_rank in [-1, 0]:\n",
    "        tb_writer.close()\n",
    "\n",
    "    return global_step, tr_loss / global_step\n",
    "\n",
    "# Evaluation of some model\n",
    "\n",
    "def evaluate(args, model: PreTrainedModel, tokenizer: PreTrainedTokenizer, df_trn, df_val, prefix=\"\") -> Dict:\n",
    "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "    eval_output_dir = args.output_dir\n",
    "\n",
    "    eval_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=True)\n",
    "    os.makedirs(eval_output_dir, exist_ok=True)\n",
    "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
    "    # Note that DistributedSampler samples randomly\n",
    "\n",
    "    def collate(examples: List[torch.Tensor]):\n",
    "        if tokenizer._pad_token is None:\n",
    "            return pad_sequence(examples, batch_first=True)\n",
    "        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(\n",
    "        eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, collate_fn=collate, drop_last = True\n",
    "    )\n",
    "\n",
    "    # multi-gpu evaluate\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    model.eval()\n",
    "\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        inputs, labels = (batch, batch)\n",
    "        inputs = inputs.to(args.device)\n",
    "        labels = labels.to(args.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs, labels=labels)\n",
    "            lm_loss = outputs[0]\n",
    "            eval_loss += lm_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    perplexity = torch.exp(torch.tensor(eval_loss))\n",
    "\n",
    "    result = {\"perplexity\": perplexity}\n",
    "\n",
    "    output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        logger.info(\"***** Eval results {} *****\".format(prefix))\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "# Main show runner\n",
    "\n",
    "def main(df_trn, df_val):\n",
    "    args = Args()\n",
    "    \n",
    "    if args.should_continue:\n",
    "        sorted_checkpoints = _sorted_checkpoints(args)\n",
    "        if len(sorted_checkpoints) == 0:\n",
    "            raise ValueError(\"Used --should_continue but no checkpoint was found in --output_dir.\")\n",
    "        else:\n",
    "            args.model_name_or_path = sorted_checkpoints[-1]\n",
    "\n",
    "    if (\n",
    "        os.path.exists(args.output_dir)\n",
    "        and os.listdir(args.output_dir)\n",
    "        and args.do_train\n",
    "        and not args.overwrite_output_dir\n",
    "        and not args.should_continue\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
    "                args.output_dir\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Setup CUDA, GPU & distributed training\n",
    "    device = torch.device(\"cuda\")\n",
    "    args.n_gpu = torch.cuda.device_count()\n",
    "    args.device = device\n",
    "\n",
    "    # Setup logging\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n",
    "    )\n",
    "    logger.warning(\n",
    "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
    "        args.local_rank,\n",
    "        device,\n",
    "        args.n_gpu,\n",
    "        bool(args.local_rank != -1),\n",
    "        args.fp16,\n",
    "    )\n",
    "\n",
    "    # Set seed\n",
    "    set_seed(args)\n",
    "\n",
    "    config = AutoConfig.from_pretrained(args.config_name, cache_dir=args.cache_dir)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name, cache_dir=args.cache_dir)\n",
    "    model = AutoModelWithLMHead.from_pretrained(\n",
    "        args.model_name_or_path,\n",
    "        from_tf=False,\n",
    "        config=config,\n",
    "        cache_dir=args.cache_dir,\n",
    "    )\n",
    "    model.to(args.device)\n",
    "    \n",
    "    logger.info(\"Training/evaluation parameters %s\", args)\n",
    "\n",
    "    # Training\n",
    "    if args.do_train:\n",
    "        train_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False)\n",
    "\n",
    "        global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
    "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
    "\n",
    "    # Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()\n",
    "    if args.do_train:\n",
    "        # Create output directory if needed\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
    "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "        # They can then be reloaded using `from_pretrained()`\n",
    "        model_to_save = (\n",
    "            model.module if hasattr(model, \"module\") else model\n",
    "        )  # Take care of distributed/parallel training\n",
    "        model_to_save.save_pretrained(args.output_dir)\n",
    "        tokenizer.save_pretrained(args.output_dir)\n",
    "\n",
    "        # Good practice: save your training arguments together with the trained model\n",
    "        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
    "\n",
    "        # Load a trained model and vocabulary that you have fine-tuned\n",
    "        model = AutoModelWithLMHead.from_pretrained(args.output_dir)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(args.output_dir)\n",
    "        model.to(args.device)\n",
    "\n",
    "    # Evaluation\n",
    "    results = {}\n",
    "    if args.do_eval and args.local_rank in [-1, 0]:\n",
    "        checkpoints = [args.output_dir]\n",
    "        if args.eval_all_checkpoints:\n",
    "            checkpoints = list(\n",
    "                os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n",
    "            )\n",
    "            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
    "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
    "        for checkpoint in checkpoints:\n",
    "            global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
    "            prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n",
    "\n",
    "            model = AutoModelWithLMHead.from_pretrained(checkpoint)\n",
    "            model.to(args.device)\n",
    "            result = evaluate(args, model, tokenizer, df_trn, df_val, prefix=prefix)\n",
    "            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
    "            results.update(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e6b0a0aec8c6b778\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e6b0a0aec8c6b778\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/16/2020 18:52:00 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "05/16/2020 18:52:01 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/config.json from cache at cached/c3a09526c725b854c685b72cf60c50f1fea9b0e4d6227fa41573425ef4bd4bc6.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5\n",
      "05/16/2020 18:52:01 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/16/2020 18:52:01 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/config.json from cache at cached/c3a09526c725b854c685b72cf60c50f1fea9b0e4d6227fa41573425ef4bd4bc6.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5\n",
      "05/16/2020 18:52:01 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/16/2020 18:52:01 - INFO - transformers.tokenization_utils -   Model name 'microsoft/DialoGPT-small' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'microsoft/DialoGPT-small' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "05/16/2020 18:52:02 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/vocab.json from cache at cached/78725a31b87003f46d5bffc3157ebd6993290e4cfb7002b5f0e52bb0f0d9c2dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/16/2020 18:52:02 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/merges.txt from cache at cached/570e31eddfc57062e4d0c5b078d44f97c0e5ac48f83a2958142849b59df6bbe6.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/16/2020 18:52:02 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/added_tokens.json from cache at None\n",
      "05/16/2020 18:52:02 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/special_tokens_map.json from cache at None\n",
      "05/16/2020 18:52:02 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/tokenizer_config.json from cache at None\n",
      "05/16/2020 18:52:03 - INFO - filelock -   Lock 140355587845928 acquired on cached/9eab12d0b721ee394e9fe577f35d9b8b22de89e1d4f6a89b8a76d6e1a82bceae.906a78bee3add2ff536ac7ef16753bb3afb3a1cf8c26470f335b7c0e46a21483.lock\n",
      "05/16/2020 18:52:03 - INFO - transformers.file_utils -   https://cdn.huggingface.co/microsoft/DialoGPT-small/pytorch_model.bin not found in cache or force_download set to True, downloading to /notebooks/indo-openchatbot/cached/tmpz4ky_3mi\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7012e1794146a6a287d476eac99204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=351265583.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/16/2020 18:52:13 - INFO - transformers.file_utils -   storing https://cdn.huggingface.co/microsoft/DialoGPT-small/pytorch_model.bin in cache at cached/9eab12d0b721ee394e9fe577f35d9b8b22de89e1d4f6a89b8a76d6e1a82bceae.906a78bee3add2ff536ac7ef16753bb3afb3a1cf8c26470f335b7c0e46a21483\n",
      "05/16/2020 18:52:13 - INFO - transformers.file_utils -   creating metadata file for cached/9eab12d0b721ee394e9fe577f35d9b8b22de89e1d4f6a89b8a76d6e1a82bceae.906a78bee3add2ff536ac7ef16753bb3afb3a1cf8c26470f335b7c0e46a21483\n",
      "05/16/2020 18:52:13 - INFO - filelock -   Lock 140355587845928 released on cached/9eab12d0b721ee394e9fe577f35d9b8b22de89e1d4f6a89b8a76d6e1a82bceae.906a78bee3add2ff536ac7ef16753bb3afb3a1cf8c26470f335b7c0e46a21483.lock\n",
      "05/16/2020 18:52:13 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/microsoft/DialoGPT-small/pytorch_model.bin from cache at cached/9eab12d0b721ee394e9fe577f35d9b8b22de89e1d4f6a89b8a76d6e1a82bceae.906a78bee3add2ff536ac7ef16753bb3afb3a1cf8c26470f335b7c0e46a21483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/16/2020 18:52:16 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.masked_bias']\n",
      "05/16/2020 18:52:20 - INFO - __main__ -   Training/evaluation parameters <__main__.Args object at 0x7fa71889f1d0>\n",
      "05/16/2020 18:52:20 - INFO - __main__ -   Creating features from dataset file at cached\n",
      "05/16/2020 18:53:38 - INFO - __main__ -   Saving features into cached file cached/gpt2_cached_lm_512\n",
      "05/16/2020 18:53:38 - INFO - __main__ -   ***** Running training *****\n",
      "05/16/2020 18:53:38 - INFO - __main__ -     Num examples = 1\n",
      "05/16/2020 18:53:38 - INFO - __main__ -     Num Epochs = 3\n",
      "05/16/2020 18:53:38 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n",
      "05/16/2020 18:53:38 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "05/16/2020 18:53:38 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "05/16/2020 18:53:38 - INFO - __main__ -     Total optimization steps = 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78fe77c811694686a64292d0cae02421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a476cdc7b6f64e23881715bdeef6da9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Iteration', max=1.0, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7cde4923dce45c79a7a8fa08dd27328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Iteration', max=1.0, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cce88f5ae4d4db69cafb671a0a8ac2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Iteration', max=1.0, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-523c0d2a27d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-2e40fd122e2c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(df_trn, df_val)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_cache_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" global_step = %s, average loss = %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-51f1ee4ed14f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, train_dataset, model, tokenizer)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mtb_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;31m# Evaluation of some model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "main(trn_df, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-small')\n",
    "model = AutoModelWithLMHead.from_pretrained('output')\n",
    "\n",
    "# Let's chat for 5 lines\n",
    "for step in range(6):\n",
    "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
    "    # print(new_user_input_ids)\n",
    "\n",
    "    # append the new user input tokens to the chat history\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "\n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    chat_history_ids = model.generate(\n",
    "        bot_input_ids, max_length=1000,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        top_p=0.92, top_k = 50\n",
    "    )\n",
    "    \n",
    "    # pretty print last ouput tokens from bot\n",
    "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
